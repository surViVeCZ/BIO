{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "This cell contains code for loading image data from a dataset. The `load_data` function reads metadata from an Excel file and iterates over folders and images to load them into numpy arrays. The progress is displayed using the `tqdm` progress bar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(metadata_path, data_directory, num_folders=6):\n",
    "    # Read metadata from the Excel file\n",
    "    metadata = pd.read_excel(metadata_path)\n",
    "    \n",
    "    # Lists to store images and corresponding labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Count total images in the dataset directory\n",
    "    total_images = sum(1 for _ in Path(data_directory).rglob('*.png'))\n",
    "    \n",
    "    # Define finger folders for both left and right hands\n",
    "    finger_folders = [\"l_index\", \"l_little\", \"l_middle\", \"l_ring\", \"l_thumb\", \n",
    "                      \"r_index\", \"r_little\", \"r_middle\", \"r_ring\", \"r_thumb\"]\n",
    "    \n",
    "    # Initialize and display a progress bar\n",
    "    progress_bar = tqdm(total=total_images, desc='Loading images', dynamic_ncols=True)\n",
    "    \n",
    "    # Iterate over metadata rows (limited by num_folders)\n",
    "    for index, row in metadata.iterrows():\n",
    "        if index >= num_folders:\n",
    "            break\n",
    "            \n",
    "        # Iterate over finger folders\n",
    "        for finger_folder in finger_folders:\n",
    "            # Create the path for the current finger folder\n",
    "            folder_path = Path(data_directory) / str(row['id']) / finger_folder\n",
    "            \n",
    "            # Check if the folder exists\n",
    "            if folder_path.exists():\n",
    "                # List all image files in the folder\n",
    "                image_files = list(folder_path.glob(\"*.png\"))\n",
    "                \n",
    "                # Iterate over image files\n",
    "                for img_path in image_files:\n",
    "                    # Open and convert the image to a numpy array\n",
    "                    img = Image.open(img_path)\n",
    "                    img = np.array(img)\n",
    "                    \n",
    "                    # Append the image to the images list\n",
    "                    images.append(img)\n",
    "                    \n",
    "                    # Create a dictionary with image metadata for the current label\n",
    "                    label = {\n",
    "                        'id': row['id'],\n",
    "                        'gender': row['gender'],\n",
    "                        'age': row['age'],\n",
    "                        'melanin': row['melanin'],\n",
    "                        'cardiovascular_disease': row['cardiovascular disease'],\n",
    "                        'smoker': row['smoker'],\n",
    "                        'sport_hobby_with_fingers': row['sport/hobby with fingers'],\n",
    "                        'alcohol_before_scan': row['alcohol before scan'],\n",
    "                        'skin_disease': row['skin disease'],\n",
    "                        'finger': finger_folder\n",
    "                    }\n",
    "                    \n",
    "                    # Append the label dictionary to the labels list\n",
    "                    labels.append(label)\n",
    "                    \n",
    "                    # Update the progress bar\n",
    "                    progress_bar.update(1)\n",
    "                \n",
    "    # Close the progress bar after loading all images\n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Convert the images list to a numpy array and return both images and labels\n",
    "    return np.array(images), labels\n",
    "\n",
    "# You can call this function to load the data:\n",
    "images, labels = load_data(\"data_description.xlsx\", \"dataset\")\n",
    "\n",
    "\n",
    "# save them using pickle\n",
    "pickle.dump(images, open(\"images.pkl\", \"wb\"))\n",
    "pickle.dump(labels, open(\"labels.pkl\", \"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io, color\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image, target_size=(1024, 1024)):\n",
    "    # Convert image to numpy array if not already\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    # Check if the image has an alpha channel (transparency)\n",
    "    if img_array.shape[-1] == 4:\n",
    "        # Convert to RGB first, then grayscale\n",
    "        grayscale_img = color.rgb2gray(img_array[..., :3])\n",
    "    elif img_array.shape[-1] == 3:\n",
    "        # Convert to grayscale\n",
    "        grayscale_img = color.rgb2gray(img_array)\n",
    "    else:\n",
    "        # Image is already grayscale\n",
    "        grayscale_img = img_array\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    equalized_img = exposure.equalize_adapthist(grayscale_img, clip_limit=0.03)\n",
    "\n",
    "    # Scale the image to range [-1, 1]\n",
    "    scaled_img = (equalized_img * 2.0) - 1.0  # This scales the 0-1 range to -1 to 1\n",
    "\n",
    "    # Convert scaled image back to a PIL image for further processing\n",
    "    processed_image = Image.fromarray(np.uint8((scaled_img + 1) * 0.5 * 255), mode='L')\n",
    "\n",
    "    original_size = processed_image.size\n",
    "    ratio = min(target_size[0]/original_size[0], target_size[1]/original_size[1])\n",
    "    new_size = (int(original_size[0] * ratio), int(original_size[1] * ratio))\n",
    "\n",
    "    # Resize the image using the calculated size\n",
    "    processed_image = processed_image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Create a new image with the target size and a black background\n",
    "    new_image = Image.new(\"L\", target_size)\n",
    "\n",
    "    # Paste the resized image onto the center of the new image\n",
    "    new_image.paste(processed_image, ((target_size[0] - new_size[0]) // 2, (target_size[1] - new_size[1]) // 2))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def preprocess_labels(labels):\n",
    "    \n",
    "    # Assuming all dicts have the same structure\n",
    "    keys = labels[0].keys()\n",
    "    label_data = {key: np.array([dic[key] for dic in labels]) for key in keys}\n",
    "\n",
    "    # Initialize encoders\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Process categorical data\n",
    "    categorical_keys = ['gender', 'smoker', 'sport_hobby_with_fingers', 'alcohol_before_scan', 'skin_disease', 'finger']\n",
    "    categorical_data = np.stack([label_data[key] for key in categorical_keys], axis=1)\n",
    "    categorical_data_encoded = one_hot_encoder.fit_transform(categorical_data).toarray()\n",
    "\n",
    "    # Process numerical/ordinal data\n",
    "    numerical_keys = ['age']\n",
    "    numerical_data = np.stack([label_data[key] for key in numerical_keys], axis=1)\n",
    "\n",
    "    # Process data that may require custom encoding like 'melanin', 'cardiovascular_disease'\n",
    "    # For example, melanin might be encoded based on the count of 'L' and 'R' occurrences, or any domain-specific method\n",
    "    # cardiovascular_disease might be one-hot encoded if it has standard categories, or label-encoded if it's more like a ranking\n",
    "\n",
    "    # For now, we'll just use the age directly and ignore other complex features for simplicity\n",
    "    condition_input = np.concatenate([numerical_data, categorical_data_encoded], axis=1)\n",
    "\n",
    "    return condition_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test preprocessing with one image \n",
    "processed_image = preprocess_image(images[0])\n",
    "# # Display the preprocessed first image\n",
    "plt.imshow(processed_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Enhanced Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing images\n",
    "Load data from pickle files if they are already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "images = pickle.load(open(\"images.pkl\", \"rb\"))\n",
    "labels = pickle.load(open(\"labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, load images from the dataset and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import concurrent.futures\n",
    "\n",
    "preprocessed_labels = preprocess_labels(labels)\n",
    "print('Labels preprocessing done')\n",
    "\n",
    "\n",
    "# Assuming preprocess_image is a function that processes a single image\n",
    "\n",
    "def preprocess_image_parallel(image):\n",
    "    return preprocess_image(image)\n",
    "\n",
    "# Create an empty list to store preprocessed images\n",
    "preprocessed_images = []\n",
    "\n",
    "# Define the preprocessing function for parallel execution\n",
    "def preprocess_and_append(image):\n",
    "    preprocessed_image = preprocess_image_parallel(image)\n",
    "    preprocessed_images.append(preprocessed_image)\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit the preprocessing tasks\n",
    "    futures = [executor.submit(preprocess_and_append, image) for image in images]\n",
    "    \n",
    "    # Display a progress bar using tqdm\n",
    "    for _ in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc='Preprocessing Images', dynamic_ncols=True):\n",
    "        pass\n",
    "\n",
    "# Convert the list of preprocessed images to a numpy array\n",
    "preprocessed_images = np.stack(preprocessed_images, axis=0)\n",
    "\n",
    "\n",
    "# save preprocessed data to pickle files\n",
    "with open('preprocessed_images.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessed_images, f)\n",
    "    \n",
    "    \n",
    "with open('preprocessed_labels.pickle', 'wb') as f:\n",
    "    pickle.dump(preprocessed_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Description: Conditional GAN (cGAN) in Keras\n",
    "\n",
    "This code defines a Conditional Generative Adversarial Network (cGAN) architecture using Keras. A cGAN is a type of GAN that conditions the generation process on additional input information, allowing for controlled image synthesis.\n",
    "\n",
    "## Generator:\n",
    "- The generator takes noise (`z_dim`-dimensional latent vector) and a conditional input as inputs.\n",
    "- It uses a fully connected layer to combine noise and condition, followed by batch normalization for stabilization.\n",
    "- The generator then applies up-sampling layers to reach the desired image size.\n",
    "- The final layer produces an image with `tanh` activation.\n",
    "\n",
    "## Discriminator:\n",
    "- The discriminator takes an image and a conditional input as inputs.\n",
    "- It combines the image and condition through concatenation, expanding the condition to match the image size.\n",
    "- Convolutional layers process the combined input to discriminate between real and generated images.\n",
    "- The discriminator outputs a single value (logit) without using a sigmoid activation, as it will be used with a suitable loss function.\n",
    "\n",
    "## Usage:\n",
    "- The generator and discriminator are initialized using their respective classes: `Generator` and `Discriminator`.\n",
    "- The generator takes noise and condition as input and outputs a generated image.\n",
    "- The discriminator takes an image and condition as input and outputs a discrimination score.\n",
    "\n",
    "Note: This architecture is designed for conditional image generation, where the generation process is influenced by additional information (condition) beyond just random noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Generator\n",
    "class Generator():\n",
    "    \n",
    "    def __init__(self, z_dim, condition_shape, img_shape):\n",
    "        # z_dim: Dimension of the latent space (noise vector)\n",
    "        # condition_shape: Shape of the condition input (e.g., parameters like age, blood pressure)\n",
    "        # img_shape: Shape of the generated image output\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.condition_shape = condition_shape\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        self.model = self.build_generator()\n",
    "\n",
    "    def build_generator(self):\n",
    "        # Noise input (z_dim-dimensional latent vector)\n",
    "        z_input = layers.Input(shape=(self.z_dim,))\n",
    "        # Conditional input (additional information you want to condition the generation on)\n",
    "        condition_input = layers.Input(shape=(self.condition_shape,))\n",
    "        \n",
    "        # Combine noise and condition via concatenation\n",
    "        x = layers.Concatenate()([z_input, condition_input])\n",
    "        \n",
    "        # Fully connected layer that takes the combined input\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)  # Helps to stabilize training\n",
    "        \n",
    "        # Up-sampling: Increasing the dimensionality to get to the correct image size\n",
    "        x = layers.Dense(512, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)  # Further stabilization of training\n",
    "        # The final layer has a size of the product of the image dimensions (width * height * channels)\n",
    "        x = layers.Dense(np.prod(self.img_shape), activation='tanh')(x)  # 'tanh' activation is common for GANs\n",
    "        # Reshape the output to the size of the image\n",
    "        img = layers.Reshape(self.img_shape)(x)\n",
    "        \n",
    "        # The generator model takes noise and condition as input and outputs an image\n",
    "        generator = models.Model([z_input, condition_input], img, name='generator')\n",
    "\n",
    "        return generator\n",
    "    \n",
    "class Discriminator():\n",
    "    \n",
    "    def __init__(self, img_shape, condition_shape):\n",
    "        # img_shape: Shape of the input image\n",
    "        # condition_shape: Shape of the condition input\n",
    "\n",
    "        self.img_shape = img_shape\n",
    "        self.condition_shape = condition_shape\n",
    "\n",
    "        self.model = self.build_discriminator()\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        # Image input (shape of the input image)\n",
    "        img_input = layers.Input(shape=self.img_shape)\n",
    "        # Conditional input (shape of the condition)\n",
    "        condition_input = layers.Input(shape=self.condition_shape)\n",
    "\n",
    "        # Combine image and condition via concatenation\n",
    "        # We assume that condition input is a flat vector and needs to be expanded to the image size\n",
    "        condition_input_expanded = layers.Dense(np.prod(self.img_shape))(condition_input)\n",
    "        condition_input_expanded = layers.Reshape(self.img_shape)(condition_input_expanded)\n",
    "        combined_input = layers.Concatenate()([img_input, condition_input_expanded])\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(combined_input)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "        x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "        # Flatten and add a dense layer\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(1)(x)  # Not using sigmoid activation because it will be used in combination with a loss function that expects logits\n",
    "\n",
    "        # Create the discriminator model\n",
    "        discriminator = models.Model([img_input, condition_input], x, name='discriminator')\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed files \n",
    "\n",
    "- We can use previously defined preprocessor to load images from saved binary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "with open('preprocessed_images.pickle', 'rb') as f:\n",
    "    preprocessed_images = pickle.load(f)\n",
    "\n",
    "with open('preprocessed_labels.pickle', 'rb') as f:\n",
    "    preprocessed_labels = pickle.load(f)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling (optional)\n",
    "- For training purposes, we can undersample the dataset to reduce the training time. This is optional, but recommended for initial testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LIMIT = 1000\n",
    "\n",
    "preprocessed_images = preprocessed_images[0:SAMPLE_LIMIT]\n",
    "preprocessed_labels = preprocessed_labels[0:SAMPLE_LIMIT]\n",
    "\n",
    "z_dim = 100  # This should match the z_dim you used to initialize your Generator\n",
    "batch_size = preprocessed_images.shape[0]  # Or any other batch size you want to use\n",
    "noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Image Generation testing\n",
    "\n",
    "The provided code snippet demonstrates the generation and visualization of synthetic images using a pre-trained generator.\n",
    "\n",
    "#### Generator Initialization:\n",
    "- The `Generator` class is used to initialize a generator model.\n",
    "- The `z_dim` represents the dimension of the latent space (noise vector).\n",
    "- The second parameter specifies the shape of the conditional input (preprocessed labels).\n",
    "- The third parameter defines the shape of the generated image (`(1024, 1024, 1)` in this case).\n",
    "\n",
    "#### Generating Synthetic Images:\n",
    "- The generator's `predict` method is used to generate synthetic images based on noise and preprocessed labels.\n",
    "- The `noise` is a random input to the generator, and `preprocessed_labels` provides additional conditioning information.\n",
    "\n",
    "#### Image Scaling:\n",
    "- The synthetic images are scaled from values between 0 and 1 to values between 0 and 255.\n",
    "- This scaling is done to convert the images into a format suitable for visualization and further processing.\n",
    "\n",
    "#### Visualization:\n",
    "- The code then visualizes eight small synthetic images in a 4x2 grid using Matplotlib.\n",
    "- Each subplot in the grid displays one synthetic image, reshaped to a 1024x1024 grayscale image.\n",
    "- The `cmap='gray'` argument specifies the grayscale color map.\n",
    "\n",
    "Note: The quality and diversity of the generated images depend on the training of the generator model and the quality of the input noise and labe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator with appropriate parameters\n",
    "generator = Generator(z_dim, preprocessed_labels.shape[1], (1024, 1024, 1))\n",
    "\n",
    "# Generate synthetic images using the generator model\n",
    "synthetic_images = generator.model.predict([noise, preprocessed_labels])\n",
    "\n",
    "# Scale the numpy array from values between 0 and 1 to values between 0 and 255\n",
    "synthetic_images = (synthetic_images * 255).astype(np.uint8)\n",
    "\n",
    "# Print the number of generated synthetic images\n",
    "print(\"Number of Synthetic Images:\", len(synthetic_images))\n",
    "\n",
    "# Plot eight small synthetic images in a 4x2 grid\n",
    "fig, axes = plt.subplots(4, 2, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over synthetic images and corresponding subplots\n",
    "for img, ax in zip(synthetic_images, axes):\n",
    "    # Reshape the image and display it in grayscale\n",
    "    # add label: uninitialized images\n",
    "    ax.imshow(img.reshape(1024, 1024), cmap='gray')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone generator training (optional)\n",
    "- Since generator takes much longer to train than discriminator, we can train it separately from the rest of the GAN.\n",
    "- Generator can be also trained using a standalone python script, which is useful for running on a remote machine, such as GPU cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the number of iterations over each image\n",
    "iterations = 10\n",
    "\n",
    "# Define the optimizer and loss function for the generator\n",
    "generator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "mse_loss = MeanSquaredError()\n",
    "\n",
    "# Compile the generator model\n",
    "generator.model.compile(optimizer=generator_optimizer, loss=mse_loss)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(iterations):\n",
    "    for i in range(len(preprocessed_images)):\n",
    "        real_image = preprocessed_images[i:i+1]  # Select a single image slice\n",
    "        label = preprocessed_labels[i:i+1]       # Select the corresponding label slice\n",
    "\n",
    "        # Generate noise\n",
    "        noise = np.random.normal(0, 1, (1, z_dim))\n",
    "        \n",
    "        # Generate a synthetic image\n",
    "        synthetic_image = generator.model.predict([noise, label])\n",
    "        \n",
    "        # Scale the synthetic image to match the real image range\n",
    "        synthetic_image = (synthetic_image + 1) / 2\n",
    "        \n",
    "        # Compute the loss between the synthetic and real image\n",
    "        loss = generator.model.train_on_batch([noise, label], real_image)\n",
    "        \n",
    "        # Print the loss\n",
    "        print(f'Epoch: {epoch}, Loss: {loss}')\n",
    "\n",
    "# Display a synthetic image\n",
    "        plt.imshow(synthetic_image[0].reshape(1024, 1024), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRELOAD_GENERATOR = False\n",
    "\n",
    "# Initialize the discriminator (make sure the img_shape matches the generator output)\n",
    "discriminator = Discriminator(img_shape=(1024, 1024, 1), condition_shape=preprocessed_labels.shape[1])\n",
    "generator = Generator(z_dim, preprocessed_labels.shape[1], (1024, 1024, 1))\n",
    "\n",
    "if PRELOAD_GENERATOR:\n",
    "    # Load the generator weights\n",
    "    generator.model.load_weights('generator.h5')\n",
    "\n",
    " \n",
    "# Prepare labels for real images (1s) and fake images (0s)\n",
    "real_labels = np.ones((batch_size, 1))\n",
    "fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "real_images = preprocessed_images.astype(np.float32)\n",
    "fake_images = synthetic_images.astype(np.float32)\n",
    "\n",
    "# print real and fake image in one plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "axes[0].imshow(real_images[0].reshape(1024, 1024), cmap='gray')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Real Image')\n",
    "axes[1].imshow(fake_images[0].reshape(1024, 1024), cmap='gray')\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Fake Image')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Get discriminator predictions for fake images\n",
    "fake_predictions = discriminator.model.predict([synthetic_images, preprocessed_labels])\n",
    "\n",
    "# Get discriminator predictions for real images\n",
    "real_predictions = discriminator.model.predict([real_images, preprocessed_labels])\n",
    "\n",
    "# The predictions are logits; to interpret them as probabilities, you can use the sigmoid function\n",
    "fake_probabilities = tf.sigmoid(fake_predictions)\n",
    "real_probabilities = tf.sigmoid(real_predictions)\n",
    "\n",
    "# print the probabilities\n",
    "\n",
    "print(fake_probabilities)\n",
    "print(real_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cGAN model\n",
    "Preparation of the cGAN model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Assume Generator and Discriminator classes are already defined as per previous discussion\n",
    "\n",
    "def build_cgan(generator, discriminator, z_dim, condition_shape):\n",
    "    # Make sure only the generator is trainable\n",
    "    discriminator.model.trainable = False\n",
    "    generator.model.trainable = True\n",
    "\n",
    "    # Inputs to the combined model\n",
    "    z = layers.Input(shape=(z_dim,))\n",
    "    condition = layers.Input(shape=(condition_shape,))\n",
    "    \n",
    "    # Generate an image based on noise and condition inputs\n",
    "    img = generator.model([z, condition])\n",
    "    \n",
    "    # The discriminator takes the generated image as input and gives a probability\n",
    "    valid = discriminator.model([img, condition])\n",
    "\n",
    "    # The combined model (stacked generator and discriminator)\n",
    "    cgan_model = models.Model([z, condition], valid, name='cgan')\n",
    "\n",
    "    # Compile the combined model\n",
    "    cgan_model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "    return cgan_model\n",
    "\n",
    "# Initialize the generator and discriminator\n",
    "z_dim = 100\n",
    "condition_shape = preprocessed_labels.shape[1]  \n",
    "img_shape = (1024, 1024, 1)  # Example image shape, adjust as per your data\n",
    "generator = Generator(z_dim, condition_shape, img_shape)\n",
    "discriminator = Discriminator(img_shape, condition_shape)\n",
    "\n",
    "# Build the cGAN model\n",
    "cgan = build_cgan(generator, discriminator, z_dim, condition_shape)\n",
    "\n",
    "# Now cgan is a model that, when trained, will update the generator's weights\n",
    "# to try to \"fool\" the discriminator, while the discriminator's weights remain fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compile the discriminator and cGAN models\n",
    "discriminator.model.compile(optimizer=Adam(0.002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cgan.compile(optimizer=Adam(0.002, 0.5), loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "print(\"CGAN and Discriminator compiled\")\n",
    "\n",
    "epochs = 10  # Number of epochs to train for\n",
    "batch_size = 2  # Size of the batch\n",
    "\n",
    "# Convert labels to float32 for consistency\n",
    "preprocessed_labels = preprocessed_labels.astype(np.float32)\n",
    "\n",
    "# Get the number of batches per epoch\n",
    "num_batches = int(preprocessed_images.shape[0] / batch_size)\n",
    "\n",
    "\n",
    "idx = np.random.randint(0, preprocessed_images.shape[0], batch_size)\n",
    "labels = preprocessed_labels[idx]\n",
    "\n",
    "# Generate a batch of fake images\n",
    "noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "gen_imgs = generator.model.predict([noise, labels])\n",
    "\n",
    "# plot images \n",
    "gen_imgs = (gen_imgs * 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(gen_imgs[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# print generator weights \n",
    "generator.model.summary()\n",
    "\n",
    "# update weights of generator\n",
    "generator.model.trainable = True\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in range(num_batches):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Get a batch of real images\n",
    "        idx = np.random.randint(0, preprocessed_images.shape[0], batch_size)\n",
    "        real_imgs = preprocessed_images[idx]\n",
    "        labels = preprocessed_labels[idx]\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.model.predict([noise, labels])\n",
    "\n",
    "        # Labels for real and fake data\n",
    "        valid_y = np.ones((batch_size, 1))\n",
    "        fake_y = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.model.train_on_batch([real_imgs, labels], valid_y)\n",
    "        d_loss_fake = discriminator.model.train_on_batch([gen_imgs, labels], fake_y)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # We want the generator to trick the discriminator, so we label the generated images as real\n",
    "        g_loss = cgan.train_on_batch([noise, labels], valid_y)\n",
    "\n",
    "        # If at the end of the epoch, save models, print out stats, or adjust learning rates if necessary\n",
    "        print(f\"{epoch}/{epochs} [D loss: {d_loss[0]}, acc: {100*d_loss[1]}] [G loss: {g_loss}]\")\n",
    "        \n",
    "    # generate and plot image to test generator\n",
    "    noise = np.random.normal(0, 1, (1, z_dim))\n",
    "    label = preprocessed_labels[0:1]\n",
    "    gen_img = generator.model.predict([noise, label])\n",
    "    gen_img = (gen_img * 255).astype(np.uint8)\n",
    "    plt.imshow(gen_img[0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# After training is complete, save your models\n",
    "generator.model.save('generator_model.h5')\n",
    "discriminator.model.save('discriminator_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final image generation\n",
    "You can extract generator and use standalone generator script to generate images. Since the generator is already trained.   \n",
    "Or you can load batch of labels and use this snippet to generate images. Here we assume that labels are already preprocessed and loaded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generator and discriminator \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "generator = load_model('generator_model.h5')\n",
    "discriminator = load_model('discriminator_model.h5')\n",
    "\n",
    "\n",
    "# load lables \n",
    "with open('preprocessed_labels.pickle', 'rb') as f:\n",
    "    preprocessed_labels = pickle.load(f)\n",
    "    \n",
    "\n",
    "# generate images for all labels\n",
    "z_dim = 100  # This should match the z_dim you used to initialize your Generator\n",
    "batch_size = preprocessed_labels.shape[0]  # Or any other batch size you want to use\n",
    "noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "synthetic_images = generator.model.predict([noise, preprocessed_labels])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
